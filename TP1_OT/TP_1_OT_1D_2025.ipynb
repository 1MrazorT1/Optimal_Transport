{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transport Optimal - FISE 3A - Majeure Informatique\n",
    "# TP 1 - Transport optimal Unidimensionnel\n",
    "\n",
    "Le but de ce TP est de se familiariser avec le formalisme du transort optimal vu en cours.\n",
    "Pour cette première séance, nous allons nous focaliser sur le calcul du transport optimal unidimensionnel (1D), plus simple, pour lequel il existe des solutions algorithmiques simples (histogrammes cumulés, permutation optimale par tri, ...).\n",
    "\n",
    "Après une première partie (I) de *rappel* sur la prise en main de python (et des bibliothèques numpy, scipy et matplotlib), nous allons implémenter (partie II) et tester ces algorithmes sur des exemples simples de transport de densités (calcul de mesure image ou **push-forward**), de transport optimal entre histogrammes discrets puis entre nuages de points. Une application à la spécification d'images (partie III) sera proposée en complément pour ceux qui souhaitent aller plus loin: \n",
    "\n",
    "- I: Prise en main de python / numpy / scipy / matplotlib \n",
    "- II:  Calcul du transport sur des densités, des histogrammes et des nuages de points \n",
    "- III: Application à la spécification d'images\n",
    "\n",
    "La partie II servira de base pour l'examen final.\n",
    "\n",
    "Ce document complété est à rendre pour le 17/02/2025 à 23h59.\n",
    "\n",
    "#### julien (point) rabin @ ensicaen.fr - 2025\n",
    "\n",
    "![](fig/logoENSI.png)\n",
    "![](fig/logoPython.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## Nom : \n",
    "\n",
    "### Prénom :\n",
    "\n",
    "### Binôme :\n",
    "\n",
    "#### Groupe de TP :\n",
    "\n",
    "#### Majeure / Spécialité :\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents :\n",
    "<a class=\"anchor\" id=\"toc\"></a>\n",
    "* [I. Introduction : random variables with python/numpy/scipy and change of variable  ](#section_1)\n",
    "    * [I-1. 1D probability distribution function (PDF)](#section_1_1)\n",
    "    * [I-2. 1D random variables](#section_1_2)\n",
    "    * [I-3. Cumulative distributions, histograms and empirical repartition function](#section_1_3)\n",
    "* [II. Push-forward and Optimal Transport](#section_2)\n",
    "    * [II.1 - reminders about change of variable with random variables](#section_2_1)\n",
    "    * [II.2 - application to push-forward ](#section_2_2)\n",
    "    * [II.3 - Wasserstein distance between 1D histograms and point-clouds](#section_2_3)\n",
    "    * [II.4 - Optimal mapping between 1D histograms](#section_2_4)\n",
    "    * [II.5 - Interpolation between 1D pdfs and point-clouds](#section_2_5)\n",
    "\n",
    "* [III. - Optimal mapping between 1D histograms : application to image specification](#section_3)\n",
    "    * [III.1 - Equalization with histograms](#section_3_1)\n",
    "    * [III.2 - Specification with histograms](#section_3_2)\n",
    "    * [III.3 - Specification with point-clouds](#section_3_3)\n",
    "\n",
    "\n",
    "[ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# I. Introduction : random variables with python/numpy/scipy and change of variable \n",
    "<a class=\"anchor\" id=\"section_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plt.rcParams['text.usetex'] = False # set to True to use Latex in plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import display, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# I-1. 1D probability distribution function (PDF)\n",
    "<a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "1D Gaussian probability distribution function (pdf) $\\mathcal N(\\mu,\\sigma^2)$ (**please complete**)\n",
    "$$\n",
    "    \\mathcal N(\\mu,\\sigma^2) (x) = \\frac{1}{\\sqrt{2 \\pi ...}} \\exp(-\\tfrac{ (x-\\mu)^2 }{2 \\sigma^2})\n",
    "$$\n",
    "\n",
    "1D Uniform pdf on segment [a,b] $\\mathcal U([a,b])$ (**please complete**)\n",
    "$$\n",
    "    \\mathcal U([a,b]) (x) = ... \\mathbb {I}_{[a,b]}(x)\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\mathbb{I}_{A}(x) =\n",
    "\\begin{cases} \n",
    "1 & \\text{if } x \\in A, \\\\\n",
    "0 & \\text{if } x \\notin A.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Implement these functions and plot them for some parameters $a$, $b$, $\\mu$ and $\\sigma^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this code\n",
    "MyUniform = lambda t,a,b : ...\n",
    "MyGauss = lambda x,mu,sig : ...\n",
    "\n",
    "N = 100\n",
    "x = np.linspace(-3.,3.,N)\n",
    "\n",
    "a,b = ...\n",
    "mu, sig = ...\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,MyGauss(x,mu,sig)) # , label =f\"$\\mathcal N({mu},{sig**2})$\"\n",
    "plt.plot(x,MyUniform(x,a,b)) # , label = f\"$\\mathcal U({a},{b})$\"\n",
    "plt.title(\"gaussian and uniform pdf\")\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : how to check *numerically* that this function is normalized, that is : \n",
    "1. $$\n",
    "    f(x) \\ge 0\n",
    "$$\n",
    "Hints : you may use `np.all`\n",
    "\n",
    "2. $$\n",
    "    \\int_{x\\in \\mathbb R} f(x) dx = 1\n",
    "$$\n",
    "Hints : you may use `np.sum` and you need do compute $dx$ from `x`; $dx$ is a constant for a regular grid of points $x$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`scipy.stats.norm.pdf` corresponds to the centered ($\\mu=0$) and normalized ($\\sigma=1$) gaussian pdf:\n",
    "$$\n",
    "    f(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}}\n",
    "$$\n",
    " `scipy.stats.uniform.pdf` corresponds to $\\mathcal U([0,1])$\n",
    "\n",
    "Use these functions to check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## I-2. 1D random variables\n",
    "<a class=\"anchor\" id=\"section_1_2\"></a>\n",
    "\n",
    "Let $Z \\sim \\mathcal N(0,1)$ and $U \\sim \\mathcal U([0,1])$ be two random variables, (gaussian and uniform)\n",
    "\n",
    "We want to generate a random variable $X \\sim \\mathcal N(\\mu,\\sigma^2)$ and $V \\sim \\mathcal U([a,b])$\n",
    "\n",
    "The change of variable between $X$ and $Z$ is (**please complete**)\n",
    "$$\n",
    "    X = ... Z ...\n",
    "$$\n",
    "\n",
    "Likewise, the change of variable between $V$ and $U$ is (**please complete**)\n",
    "$$\n",
    "    V = ... U ...\n",
    "$$\n",
    "\n",
    "1 - Implement these change of variables to generate two random arrays of $n$ samples $X \\in \\R^n$ and $V \\in [a,b]^n$ \n",
    "\n",
    "2 - compute & plot the histogram for some parameters $a$, $b$, $\\mu$ and $\\sigma^2$ \n",
    "\n",
    "3 - compare with the pdf (beware of the normalisation of the histogram !)\n",
    "\n",
    "hints : \n",
    "- use `np.random.rand` or `scipy.stats.uniform.rvs` to generate $U$\n",
    "- use `np.random.randn` or `scipy.stats.norm.rvs` to generate $Z$\n",
    "- use `np.histogram` & `np.stairs` to compute & plot histograms and bin indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# sampling\n",
    "n = 10_000\n",
    "U = ...\n",
    "Z = ...\n",
    "\n",
    "# change of variables\n",
    "a,b = ...\n",
    "V = ...\n",
    "mu, sig = ...\n",
    "X = ...\n",
    "\n",
    "# histograms\n",
    "N = 100\n",
    "x = ...\n",
    "h_X,bins_x = ...\n",
    "h_V,bins_v = ...\n",
    "\n",
    "# normalization\n",
    "h_X = ...\n",
    "h_V = ...\n",
    "\n",
    "plt.figure()\n",
    "plt.stairs(h_X, bins_x, label= \"\")\n",
    "plt.stairs(h_V, bins_v, label= \"\")\n",
    "plt.plot(x,MyGauss(x,mu,sig), label = \"\")\n",
    "plt.plot(x,MyUniform(x,a,b), label = \"\")\n",
    "plt.title(\"TITLE\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## I.3. Cumulative distributions, histograms and empirical repartition function\n",
    "<a class=\"anchor\" id=\"section_1_3\"></a>\n",
    "\n",
    "[Table of Contents (top)](#toc)\n",
    "\n",
    "Let $f: \\mathbb R \\rightarrow \\mathbb R$ be a pdf.\n",
    "The cumulative probability distribution $F : \\mathbb R \\rightarrow [0,1]$ is defined as :\n",
    "$$\n",
    "F^{} (x) = \\int_{\n",
    "y \\in (-\\infty,x]} \\;\n",
    "f(y) \\, dy\n",
    "$$\n",
    "\n",
    "The pseudo-inverse cumulative distribution $F^{-1} : [0,1]\\rightarrow \\mathbb R \\cup \\{-\\infty\\}$ is defined as :\n",
    "$$\n",
    "F^{-1} (t) = \\inf_x \\left \\{ \n",
    "x \\in \\mathbb R \\cup \\{-\\infty\\}, \\;\n",
    "F(x) \\ge t\n",
    "\\right \\}\n",
    "$$\n",
    "\n",
    "The empirical estimation of $F$ can be obtained by :\n",
    "- knowing $f$, computing approximately the integral (e.g. using `numpy.cumsum()`)\n",
    "- using random samples, compute the cumulative histogram (e.g. using `np.histogram' and `numpy.cumsum()`) \n",
    "- using sorted point cloud (e.g. using `numpy.sort()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - compute the cumulative distribution of $\\mathcal N(\\mu,\\sigma^2)$ and $\\mathcal U ([a,b])$\n",
    "$$\n",
    "    F(x_i) \\approx \\sum_{j\\le i} f(x_j) (x_{j+1} - x_j )\n",
    "$$\n",
    "where $f(x_i)$ are the pdf values on points $(x_i)$ sampled on a regular grid\n",
    "\n",
    "2 - compare with the empirical cumulative histograms\n",
    "$$\n",
    "    H[i] = \\sum_{j\\le i} h[j]\n",
    "$$\n",
    "where $h$ is the histogram computed from a random sample\n",
    "\n",
    "3 - compare with the empirical repartition function :\n",
    "- generate a random n-sample $X = (X_1, \\ldots X_n)$\n",
    "- sort values in ascending order : $X \\circ \\sigma$ such that $X_{ \\sigma (1)} < X_{ \\sigma (2)} < \\ldots < X_{ \\sigma (n)}$\n",
    "- plot points $(X_{ \\sigma (i)}, \\frac{i}{n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# II . push-forward and optimal transport\n",
    "<a class=\"anchor\" id=\"section_2\"></a>\n",
    "[Table of Contents (top)](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1 - reminders about change of variable with random variables\n",
    "<a class=\"anchor\" id=\"section_2_1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Recall about push-forward :\n",
    "\n",
    "Let $\\mu$ and $\\nu$ two probability measures with densities $f$ and $g$ respectively \n",
    "$$\\mu(dx) = f(x)dx \\text{ and } \\nu(dx) = g(x)dx.$$\n",
    "\n",
    "Let $T$ be a mapping such that the push-foward of $\\mu$ with $T$ match $\\nu$ which is noted as\n",
    "$$\n",
    "    T_\\# \\mu = \\nu\n",
    "$$\n",
    "Then pdfs verifies (see course) : (**please complete**)\n",
    "$$\n",
    "    f(x) = g \\circ T(x) \\times ...\n",
    "$$\n",
    "where $T'$ indicates the derivative of the mapping\n",
    "\n",
    "Conversely, we have  (**please complete**)\n",
    "$$\n",
    "    g(y) = f \\circ T^{-1}(y) \\times ...\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2 - application of push-forward to pdf\n",
    "<a class=\"anchor\" id=\"section_2_2\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Questions : \n",
    "\n",
    "- what happen to the pdf $f(x)$ when using a change of variable $x=T^{-1}(y)$ ? is it still a pdf ?\n",
    "\n",
    "- to illustrate your answer, plot $y \\mapsto f\\circ T^{-1}(y)$ for a gaussian $f_1 = \\mathcal N(\\mu,\\sigma^2)$ and a uniform pdf $f_2 = \\mathcal U ([a,b])$, \n",
    "combined with increasing functions:\n",
    "    - an affine map : $ y = T(x) = \\alpha x+\\beta $\n",
    "    - a non-linear bijective map : $ y = T(x) = e^{\\gamma x}$\n",
    "    - (bonus) $y = x^2$ (Note : not bijective !)\n",
    "    - (bonus) $y = x^3$ (Note : special required with sign in numpy)\n",
    "\n",
    "- describes what happen when using the proper change of variable which requires the derivative :\n",
    "$$\n",
    "    g(y) = f \\circ T^{-1}(y) \\times ...\n",
    "$$\n",
    "\n",
    "- check your result by \n",
    "    - drawing random samples $X$ from $f_1$ and $f_2$\n",
    "    - apply the change of variable $Y = T(X)$\n",
    "    - plot the normalized histogram of $Y$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here :\n",
    "f = ... # pdf function with approriate parameters\n",
    "\n",
    "N = 1_000 # number of points\n",
    "x = np.linspace(...,N)\n",
    "\n",
    "n = 100_000 # random sample size\n",
    "X = ...\n",
    "\n",
    "y = np.linspace(...,N)\n",
    "T_inv = ...\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,f(x)) # , label = \"$f$\"\n",
    "plt.plot(y,f(T_inv)) # , label = \"$ f \\circ T^{-1} $\"\n",
    "plt.title(\"Changement de variable\")\n",
    "plt.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II-3. Wasserstein distance between 1D histograms & 1D point-clouds\n",
    "<a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $\\mu$ and $\\nu$ two 1D probability measures with densities $f$ and $g$ respectively \n",
    "$$\\mu(dx) = f(x)dx \\text{ and } \\nu(dx) = g(x)dx.$$\n",
    "\n",
    "In the original setting of the Monge transportation setting when using a cost function $c(x,y) = |x-y|$, the optimal transport cost is the Wasserstein-1 distance :\n",
    "$$\n",
    "    W_1(\\mu, \\nu) = \\int_{\\mathbb R} \\lvert F(x) - G(x) \\rvert dx = \\|F-G\\|_{1}\n",
    "$$\n",
    "\n",
    "In the case where $c(x,y) = |x-y|^2$, the optimal transport cost is the *quadratic* Wasserstein-2 distance :\n",
    "$$\n",
    "    W_2(\\mu, \\nu)^2 = \\int_{[0,1]} \\lvert F^{-1}(t) - G^{-1}(t) \\rvert^2 dt = \\|F^{-1}-G^{-1}\\|_{2}^2\n",
    "$$\n",
    "which requires to compute the pseudo-inverse of the cumulative distribution functions (CDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "1 - compute the Wasserstein-1 distance between two gaussian distributions \n",
    "$f_0 = \\mathcal N(\\mu_0,\\sigma_0^2)$ and $f_1 = \\mathcal N(\\mu_1,\\sigma_1^2)$\n",
    "\n",
    "then, check numerically that $W_1(f_0,f_1) = |\\mu_1 - \\mu_0|$ when $\\sigma_0 = \\sigma_1$\n",
    "\n",
    "then, check numerically that the corresponding transport cost using $c(x,y) = |x-y|$ with the optimal map $T_{0\\rightarrow 1}$ gives the same result :\n",
    "$$\n",
    "    OT(f_0,f_1) = \\int_{\\mathbb R} |T_{0\\rightarrow 1}(x) - x| f_0(x) dx\n",
    "$$\n",
    "$$\n",
    "    T_{0\\rightarrow 1}(x) = \\tfrac{\\sigma_1}{\\sigma_0} (x-\\mu_0) + \\mu_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "2 - compute the Wasserstein-2 distance between two gaussian distributions \n",
    "$f_0 = \\mathcal N(\\mu_0,\\sigma_0^2)$ and $f_1 = \\mathcal N(\\mu_1,\\sigma_1^2)$\n",
    "\n",
    "check numerically that $W_2(f_0,f_1)^2 = |\\mu_1 - \\mu_0|^2 + (\\sigma_0 - \\sigma_1)^2$ \n",
    "\n",
    "then, check numerically that the corresponding transport cost using $c(x,y) = |x-y|^2$ with the optimal map $T_{0\\rightarrow 1}$ gives the same result :\n",
    "$$\n",
    "    OT(f_0,f_1) = \\int_{\\mathbb R} |T_{0\\rightarrow 1}(x) - x|^2 f_0(x) dx\n",
    "$$\n",
    "with\n",
    "$$\n",
    "    T_{0\\rightarrow 1}(x) = \\tfrac{\\sigma_1}{\\sigma_0} (x-\\mu_0) + \\mu_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints* : recall that \n",
    "the pseudo-inverse CDF $F^{-1} : [0,1]\\rightarrow \\mathbb R \\cup \\{-\\infty\\}$ is defined as :\n",
    "$$\n",
    "F^{-1} (t) = \\inf_x \\left \\{ \n",
    "x \\in \\mathbb R \\cup \\{-\\infty\\}, \\;\n",
    "F(x) \\ge t\n",
    "\\right \\}\n",
    "$$\n",
    "\n",
    "\n",
    "**Input:** $F$ (cumulative histogram values in [0,1]), $x$ (corresponding bin values in $\\mathbb R$), $t$ (target bin values in [0,1] for inverse function)\n",
    "\n",
    "**Output:** $F_{\\text{inv}}$ (pseudo-inverse cumulative histogram for values in t $\\in$ [0,1])\n",
    "\n",
    "**Pseudo Code:**\n",
    "1. Initialize F_inv as an array of zeros with the same shape as t\n",
    "2. Set N to the size of F\n",
    "3. Set j to 0\n",
    "4. For each index i and value v in t:\n",
    "    1. While F[j] < v :\n",
    "        *   Increment j by 1\n",
    "        *  If j >= N:\n",
    "            - Set j to N - 1\n",
    "            - Break the while loop\n",
    "    1. Set F_inv[i] = x[j]\n",
    "5. Return F_inv\n",
    "\n",
    "you can use the function \n",
    "```\n",
    "    def pseudo_inverse(F,x,t) :\n",
    "        F_inv = np.zeros_like(t)\n",
    "        \n",
    "        ...\n",
    "\n",
    "        return F_inv      \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.4 - Optimal mapping between 1D point-clouds\n",
    "<a class=\"anchor\" id=\"section_2_4\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For N-point-clouds $X \\in \\mathbb R^{N \\times d}$ and $Y \\in \\mathbb R^{N \\times d}$, computing the optimal transport map $T$ boils down to compute an optimal assignment.\n",
    "\n",
    "In the 1D case (d=1), when using ground cost function $c(x,y) = |x-y|^p$ with $p\\ge 1$, \n",
    "optimal assignment can be simply obtained by **matching points with the same ordering rank**.\n",
    "\n",
    "The pseudo-algorithm writes as follows : \n",
    "1) computes permutations $\\sigma_X$ and $\\sigma_Y$ sorting $X$ and $Y$ (in increasing order) : \n",
    "$$\n",
    "    X_{\\sigma_X(1)} \\le X_{\\sigma_X(2)} \\le ... \\le X_{\\sigma_X(N)}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "    Y_{\\sigma_Y(1)} \\le Y_{\\sigma_Y(2)} \\le ... \\le Y_{\\sigma_Y(N)}\n",
    "$$\n",
    "2) defines the optimal assignement as \n",
    "$$\n",
    "    \\sigma = \\sigma_Y\\circ\\sigma_X^{-1}\n",
    "$$\n",
    "The corresponding \"mapping\" is $T: X_{\\sigma_X(i)} \\mapsto Y_{\\sigma_Y(i)}$, that is\n",
    "$$\n",
    "    T: X_i \\mapsto Y_{\\sigma_Y\\circ\\sigma_X^{-1}(i)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code (`GMM` function) to generate and visualize two random samples $X_1$ and $X_2$ from two different probability distributions.\n",
    "\n",
    "Compute the optimal assignement between the two point-clouds. Is it a 1-to-1 mapping ?\n",
    "\n",
    "Hints : a simple trick to inverse a permutation $\\sigma :  \\{1 .. N\\} \\rightarrow \\{1 .. N\\}$ in python is to explicitely use the property :\n",
    "$$\n",
    "    \\sigma^{-1} (\\sigma(i)) = i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the following code to compute optimal assignement between two set of points\n",
    "\n",
    "# Gaussian mixture\n",
    "def GMM(p = (.5,.5), mu = (0,1), sig = (1,1), N=1_000) :\n",
    "    K = len(p)\n",
    "    assert len(mu) == K\n",
    "    assert len(sig) == K\n",
    "\n",
    "    X = np.random.randn(N)\n",
    "    m = 0\n",
    "    for i in range(K-1) :\n",
    "        n = int(p[i]*N)\n",
    "        X[m:m+n] = mu[i] + sig[i] * X[m:m+n]\n",
    "        m += n\n",
    "    X[m:] = mu[K-1] + sig[K-1] * X[m:]\n",
    "\n",
    "    return X\n",
    "\n",
    "N = 10\n",
    "\n",
    "# # gaussian mixture #1\n",
    "p1 = (.3,.7)\n",
    "X1 = GMM(p1,(0,1),(1,1),N)\n",
    "\n",
    "# # gaussian mixture #2\n",
    "p2 = (.5,.3,.2)\n",
    "X2 = GMM(p2,(-.5,.5,1.5),(1,1,1),N)\n",
    "\n",
    "# define optimal assignement 1->2\n",
    "#assign_1to2 = ...\n",
    "\n",
    "# apply transport as assignment\n",
    "X12 = X2\n",
    "\n",
    "plt.figure()\n",
    "Y1 = np.zeros(N) # X1 is on the real line y=0\n",
    "Y2 = np.ones(N) # for visualization, X2 is shifted to y=1\n",
    "plt.plot(X1, Y1, 'or') # , label = \"$X_1$\"\n",
    "plt.plot(X2, Y2, 'ob') # , label = \"$X_2$\"\n",
    "plt.plot(X12, np.ones(N)) # , 'xc', label = \"$X_{12}$\"\n",
    "plt.legend()\n",
    "\n",
    "x = np.stack((X1,X12),axis=1).T\n",
    "y = np.stack((Y1,Y2),axis=1).T\n",
    "plt.plot(x, y, '--g');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal transportation cost can be computed from the optimal mapping \n",
    "$$\n",
    "    \\sigma = \\sigma_Y\\circ\\sigma_X^{-1}\n",
    "$$\n",
    "\n",
    "Recall that for uniform probability measure supported on a point-cloud, we have :\n",
    "$$\n",
    "    p(x) = \\frac 1N\\sum_{i \\in [N]} \\delta(x - x_i)\n",
    "\\text{ and }\n",
    "    q(y) = \\frac 1N\\sum_{j \\in [N]} \\delta(y - y_j)\n",
    "$$\n",
    "\n",
    "The Wasserstein-1 distance (OT with ground cost $c(x,y) = |x-y|$) is :\n",
    "$$\n",
    "    W_1(X,Y) = OT(p,q) \n",
    "    = \\frac{1}{N} \\sum_{i=1}^N |X_i - Y_{\\sigma(i)}|\n",
    "    = \\frac{1}{N} \\sum_{i=1}^N |X_{\\sigma_X(i)} - Y_{\\sigma_Y(i)}|\n",
    "$$\n",
    "\n",
    "The Wasserstein-2 distance (OT with ground cost $c(x,y) = |x-y|^2$)  is :\n",
    "$$\n",
    "    W_2(X,Y) = \\sqrt{OT(p,q)} = \\sqrt{ \\frac{1}{N} \\sum_{i=1}^N |X_i - Y_{\\sigma(i)}|^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your previous code, compute the Wasserstein distance between two large point-clouds generated from Gaussian distributions (say $N=10^5$).\n",
    "\n",
    "Compare with the Wasserstein distance between two Gaussian distributions (as done in previous question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.5 - BONUS : Interpolaton between two pdfs and point-clouds\n",
    "<a class=\"anchor\" id=\"section_2_5\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpolate between two probability measures $p_0$ and $p_1$, one can use the **Euclidean interpolation** (mixture model) :\n",
    "$$\n",
    "    p_\\lambda(x) = (1 - \\lambda) p_0 + \\lambda p_1\n",
    "$$\n",
    "\n",
    "Show that the interpolate measure $p_\\lambda$ is indeed a probability measure.\n",
    "\n",
    "Plot interpolated $p_\\lambda$ for various $\\lambda$ using the following code for Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation with euclidean distance\n",
    "P = 11 # number of interpolated pdfs\n",
    "N = int(1e2)\n",
    "x = np.linspace(-5.,5.,N)\n",
    "\n",
    "mu0, sig0 = -1,1\n",
    "p_0 = 1./sig0 * scipy.stats.norm.pdf( (x-mu0)/sig0 )\n",
    "mu1, sig1 = 1,0.5\n",
    "p_1 = 1./sig1 * scipy.stats.norm.pdf( (x-mu1)/sig1 )\n",
    "\n",
    "Lbd = np.linspace(0,1,P)\n",
    "plt.figure()\n",
    "for i,lbd in enumerate(Lbd) :\n",
    "\n",
    "    p_lbd = lbd * p_1 + (1-lbd) * p_0\n",
    "\n",
    "    Couleur = (1-lbd)*np.array((1.,0.,0.)) + lbd * np.array((0.,0.,1.))\n",
    "\n",
    "    plt.plot(x,p_lbd,color=Couleur) # label=f\"$\\lambda = {lbd:.2}$\"\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Interpolation between two Gaussians using Euclidean distance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting alternative with optimal transport is the **interpolation of the push-forward** (a.k.a McCann interpolation) using optimal transport map $T$:\n",
    "$$T_\\lambda = (1 - \\lambda) \\text{Id} + \\lambda T_{0\\rightarrow 1} $$\n",
    "\n",
    "For 1D gaussian pdfs $p_0 = \\mathcal N(\\mu_0,\\sigma_0^2)$ and $p_1 = \\mathcal N(\\mu_1,\\sigma_1^2)$ the optimal transport map for ground cost ($c(x,y) = |x-y|^p$, $p\\ge 1$) writes:\n",
    "$$T_{0\\rightarrow 1} : x \\mapsto  \\mu_1 + \\frac{\\sigma_1}{\\sigma_0}(x-\\mu_0)$$\n",
    "We can show (see course) that the interpolated pdf is gaussian: \n",
    "$$\n",
    "    p_\\lambda = \\mathcal N(\\mu_\\lambda,\\sigma_\\lambda^2)\n",
    "$$\n",
    "with \n",
    "$$\n",
    "    \\sigma_\\lambda =  (1 - \\lambda) \\sigma_0 + \\lambda {\\sigma_1}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "    \\mu_\\lambda = (1 - \\lambda) \\mu_0 + \\lambda {\\mu_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For various $\\lambda \\in [0,1]$ :\n",
    "- Define the interpolated optimal map $T_\\lambda$ and computes numerically the corresponding push-forward $T_\\lambda {}_\\# p_0 = p_\\lambda$\n",
    "as done in [II.2 - application to push-forward ](#section_2_2)\n",
    "\n",
    "- in the gaussian case, compare with the closed-form formula of interpolated pdf given above to check your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus : Experiment with non-Gaussian pdfs (for instance using gaussian mixtures obtained by Euclidean Interpolation as provided by the code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus : Experiment with non-Gaussian point-clouds (for instance using gaussian mixtures with the function `GMM`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# III - BONUS : Optimal transport between 1D histograms : application to image specification \n",
    "<a class=\"anchor\" id=\"section_3\"></a>\n",
    "\n",
    "\n",
    "[Table of Contents (top)](#toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 1D pdfe $f$ (source) and $g = T_\\# f$ (target) with a differential transport map $T$, we have the relation (see course)\n",
    "$$\n",
    "    g \\circ T(x) \\, |T'(x)| = f(x) \n",
    "$$\n",
    "Considering cumulative distribution functions $F$ and $G$ and an *increasing* monotonic map $T$, this boils down to\n",
    "$$\n",
    "    G \\circ T = F\n",
    "$$\n",
    "The resulting map satisfies\n",
    "$$\n",
    "    T = G^{-1} \\circ F\n",
    "$$\n",
    "using the pseudo-inverse of $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### III.1 - Equalization using histograms\n",
    "<a class=\"anchor\" id=\"section_3_1\"></a>\n",
    "\n",
    "Let assume that $x \\in [0,1]$ for simplicity.\n",
    "For a target uniform distribution, we have $g(x) = \\mathbb 1_{[0,1]}(x)$.\n",
    "Then $G(x) = x = G^{-1}(x)$\n",
    "The transport map writes simply :\n",
    "$$\n",
    "    T = F\n",
    "$$\n",
    "\n",
    "If $x \\in [a,b]$, $g(x) = \\tfrac 1{b-a} \\mathbb 1_{[a,b]}(x)$ and \n",
    "$G(x) = \\tfrac {x-a}{b-a}$ and $G^{-1}(t) = (b-a)t+a$.\n",
    "$$\n",
    "    T(x) = (b-a) F(x) + a\n",
    "$$\n",
    "For 8-bit images, pixel values are between a=0 and b=255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following code to perform gray values equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this code !\n",
    "# experiment on a gray valued image\n",
    "\n",
    "im0 = plt.imread(\"pics/flower_gray.jpg\")\n",
    "H,W,C = im0.shape\n",
    "print(f\"input range : [{im0.min()},{im0.max()}]\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(im0,cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "im = im0[:,:,0].copy() # select only one channel\n",
    "X = im.reshape(-1) # 1D point cloud\n",
    "bins = np.arange(257) # 0 to 256\n",
    "f = ... # histogram (pdf)\n",
    "F = ... # cumulative probability functio (CDF)\n",
    "\n",
    "fig0, ax0 = plt.subplots()\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax0.stairs(f,bins,label=\"empirical hist\")\n",
    "ax1.stairs(F,bins,label=\"empirical rep. fun.\")\n",
    "\n",
    "# define transport map from F\n",
    "T = ...\n",
    "# apply transport map (on already quantized pixel values) X\n",
    "Y = ...\n",
    "\n",
    "# for visualisation : compute the histogram g and CDF G\n",
    "g = ... \n",
    "G = ...\n",
    "\n",
    "ax0.stairs(g,bins,label=\"hist after transport\")\n",
    "ax0.legend()\n",
    "ax1.stairs(G,bins,label=\"empirical rep. fun. after transport\")\n",
    "ax1.legend()\n",
    "\n",
    "# reshape Y as an image\n",
    "im = Y.reshape(H,W,1)\n",
    "im = np.repeat(im, 3, axis=2)\n",
    "print(f\"output range : [{im.min()},{im.max()}]\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(im/255,cmap='gray')  # /255 because float image should be in [0,1]\n",
    "plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### III.2 - Specification using histograms\n",
    "<a class=\"anchor\" id=\"section_3_2\"></a>\n",
    "\n",
    "Now we consider an arbritrary target histogram / pdf $g(x)$, which requires to compute the pseudo-inverse CDF $G^{-1}$ to compute the optimal map :\n",
    "$$\n",
    "    T = G^{-1} \\circ F\n",
    "$$\n",
    "\n",
    "Define a function to compute $T$ from a CDF $F$ and $G$.\n",
    "\n",
    "Apply this function to specificy RGB channels of a color image given a target image\n",
    "\n",
    "Note : one can use the previously defined function defined ```pseudo_inverse```, but here we can take advantage of the fact that both $F$ and $G$ are on quantized values {0,..255}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this code\n",
    "\n",
    "# experiment on image pairs :\n",
    "im1 = plt.imread(\"pics/flashno_1_small.jpg\")\n",
    "H1,W1,C = im1.shape\n",
    "im2 = plt.imread(\"pics/flash_2_small.jpg\")\n",
    "H2,W2,C = im2.shape\n",
    "print(f\"input range : [{im1.min()},{im1.max()}]\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(np.concatenate((im1,im2), axis=1),cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "im_rgb = im1.copy()\n",
    "for c in range(C):\n",
    "    x1 = im1[:,:,c].copy() # select only one channel\n",
    "    X1 = x1.reshape(-1)\n",
    "    x2 = im2[:,:,c].copy() # select only one channel\n",
    "    X2 = x2.reshape(-1)\n",
    "\n",
    "    # compute CDF\n",
    "    bins = np.arange(257)\n",
    "    f1 = ...\n",
    "    F1 = ...\n",
    "    f2 = ...\n",
    "    F2 = ...\n",
    "\n",
    "    fig0, ax0 = plt.subplots()\n",
    "    ax0.stairs(f1/f1.max(),bins,label=\"empirical hist1\", linewidth = 4, alpha=.5)\n",
    "    ax0.stairs(f2/f2.max(),bins,label=\"empirical hist2\", linewidth = 4, alpha=.5)\n",
    "    ax0.stairs(F1,bins,label=\"empirical rep. fun. 1\", linewidth = 4, alpha=.5)\n",
    "    ax0.stairs(F2,bins,label=\"empirical rep. fun. 2\", linewidth = 4, alpha=.5)\n",
    "\n",
    "    # define $T = F2^{-1} \\circ F1$\n",
    "    T = ...\n",
    "\n",
    "    # apply transport map T\n",
    "    X12 = T[X1]\n",
    "\n",
    "\n",
    "    # compute resulting CDF\n",
    "    g = ...\n",
    "    G = ...\n",
    "\n",
    "    ax0.stairs(g/g.max(),bins,label=\"hist after transport\", linewidth = 2, alpha=.9)\n",
    "    ax0.legend()\n",
    "    ax0.stairs(G,bins,label=\"empirical rep. fun. after transport\", linewidth = 2, alpha=.9)\n",
    "    ax0.legend()\n",
    "\n",
    "    im_rgb[:,:,c] = X12.reshape(H1,W1)\n",
    "    print(f\"output range : [{X12.min()},{X12.max()}]\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(im_rgb/255,cmap='gray')  # /255 because float image should be in [0,1]\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### III.3 - Specification using point-cloud optimal assignment\n",
    "<a class=\"anchor\" id=\"section_3_3\"></a>\n",
    "\n",
    "Using sorting algorithms, achieve this task using optimal assignment between point-clouds of gray values.\n",
    "\n",
    "How the two methods differs in terms of time complexity and optimal mapping ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder : For N-point-clouds in the 1D case, optimal assignment can be simply defined by matching points with the same ordering rank.\n",
    "The specification writes as follows : \n",
    "1) computes permutations $\\sigma_X$ and $\\sigma_Y$ sorting $X$ and $Y$ (in increasing order) : \n",
    "$$\n",
    "    X_{\\sigma_X(1)} \\le X_{\\sigma_X(2)} \\le ... \\le X_{\\sigma_X(N)}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "    Y_{\\sigma_Y(1)} \\le Y_{\\sigma_Y(2)} \\le ... \\le Y_{\\sigma_Y(N)}\n",
    "$$\n",
    "2) defines \"mapping\" as $T: X_{\\sigma_X(i)} \\mapsto Y_{\\sigma_Y(i)}$, that is\n",
    "$$\n",
    "    T: X_i \\mapsto Y_{\\sigma_Y\\circ\\sigma_X^{-1}(i)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this code\n",
    "\n",
    "if im1.shape != im2.shape :\n",
    "    raise \"the two images should have the same size !\"\n",
    "\n",
    "N = H1*W1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(np.concatenate((im1,im2), axis=1),cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "im_rgb2 = im1.copy()\n",
    "for c in range(C):\n",
    "    x1 = im1[:,:,c].copy() # select only one channel\n",
    "    X1 = x1.reshape(-1)\n",
    "    x2 = im2[:,:,c].copy() # select only one channel\n",
    "    X2 = x2.reshape(-1)\n",
    "\n",
    "    # sort each channel values\n",
    "    ...\n",
    "\n",
    "    # define optimal assignement 1->2\n",
    "    ...\n",
    "\n",
    "    # apply transport as assignment\n",
    "    X12 = ...\n",
    "\n",
    "    im_rgb2[:,:,c] = X12.reshape(H1,W1)\n",
    "    print(f\"output range : [{X12.min()},{X12.max()}]\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(im_rgb2/255,cmap='gray')  # /255 because float image should be in [0,1]\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
